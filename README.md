# PUNTO 1 â€” Web Scraping Concurrente de Herramientas ElectrÃ³nicas (Selenium + Hilos + Mutex + SemÃ¡foro)

# DescripciÃ³n General

El primer punto del proyecto consiste en desarrollar un sistema automatizado de Web Scraping capaz de obtener mÃ­nimo 200 imÃ¡genes de diferentes herramientas utilizadas en los laboratorios de ingenierÃ­a electrÃ³nica, tales como:

-Raspberry Pi

-Generador de seÃ±ales

-Osciloscopio

-Fuente dual

-Destornillador

-Pinzas

-Condensador

-Transistor

-Bombilla

El objetivo final es construir la base de datos visual que alimentarÃ¡ los siguientes puntos del proyecto (ETL, clasificaciÃ³n, despliegue).

Para garantizar alto rendimiento, el sistema implementa:

Hilos (threads) para paralelismo real.

SemÃ¡foro para evitar crear demasiadas instancias de navegador.

Mutex (Lock) para proteger las operaciones de escritura en disco.

Selenium + WebDriver Manager para abrir bÃºsquedas reales en Mercado Libre y capturar imÃ¡genes de cada producto.

# Arquitectura del Sistema de Scraping

```mermaid
flowchart TD
    CENTRAL((Sistema de Scraping))

    MAIN[MAIN THREAD]
    WORKER[WORKER THREAD x10]
    DOWN[DOWNLOADER Mutex]

    SUB1[Crea lista de productos]
    SUB2[Lanza hilos en paralelo]

    SUB3[Pide turno al semaforo]
    SUB4[Abre Selenium headless]
    SUB5[Extrae URLs de imagenes]
    SUB6[Envia URLs al downloader]

    SUB7[Descarga imagenes]
    SUB8[Protege escritura]
    SUB9[Guarda archivos por producto]

    CENTRAL --> MAIN
    CENTRAL --> WORKER
    CENTRAL --> DOWN

    MAIN --> SUB1
    MAIN --> SUB2

    WORKER --> SUB3
    WORKER --> SUB4
    WORKER --> SUB5
    WORKER --> SUB6

    DOWN --> SUB7
    DOWN --> SUB8
    DOWN --> SUB9

    MAIN --> WORKER --> DOWN



```
Descarga segura mediante la librerÃ­a requests.

Este diseÃ±o permite recolectar miles de imÃ¡genes de forma rÃ¡pida, controlada y segura.


##  TecnologÃ­as Utilizadas

| TecnologÃ­a        | Uso                                                     |
|------------------|----------------------------------------------------------|
| **Python 3**     | LÃ³gica principal del sistema                             |
| **Selenium**     | NavegaciÃ³n web real y extracciÃ³n de imÃ¡genes             |
| **WebDriver Manager** | GestiÃ³n automÃ¡tica de ChromeDriver                  |
| **Requests**     | Descarga directa de imÃ¡genes                             |
| **Threads (Hilos)** | Paralelismo para aumentar velocidad                   |
| **Semaphore**    | Controla el nÃºmero de navegadores simultÃ¡neos            |
| **Lock / Mutex** | Evita conflictos en la escritura a disco                 |


# Modelo de Concurrencia: Hilos + SemÃ¡foro + Mutex

Este scraping fue diseÃ±ado con ingenierÃ­a de concurrencia, no simplemente con Python secuencial.

Hilos (threads)

Cada producto se procesa en un hilo independiente.
Esto permite descargar imÃ¡genes de varios productos simultÃ¡neamente.

 SemÃ¡foro (threading.Semaphore)

Abrir muchos navegadores Chrome simultÃ¡neamente consume mucha RAM.
Por eso, se limita a 3 navegadores mÃ¡ximo en paralelo:

``` python

browser_semaphore = threading.Semaphore(3)

```
Solo 3 hilos pueden abrir Selenium a la vez.
Los demÃ¡s esperan su turno.

 Mutex (threading.Lock)

Cuando varios hilos descargan imÃ¡genes al mismo tiempo existe riesgo de:

 -Archivos corruptos

-Colisiones escribiendo el mismo nombre

-Directorios bloqueados

Para evitarlo:

``` python

with file_lock:
    with open(filename, "wb") as f:
        f.write(img.content)

```
Solo un hilo escribe a disco a la vez â†’ 100% seguro.

# CÃ³digo utilizado para el scraping

``` python


from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
import threading
import time
import os
import requests

# ============================
# LISTA DE PRODUCTOS
# ============================
productos = [
    "multimetro", "raspberry", "generador de seÃ±ales", "osciloscopio",
    "fuente dual", "destornillador", "pinzas", "condensador",
    "transistor", "bombilla"
]

# ============================
# CARPETA BASE
# ============================
BASE_DIR = "scraping/images/"
os.makedirs(BASE_DIR, exist_ok=True)

# ============================
# MUTEX (SECCIÃ“N CRÃTICA DE ESCRITURA)
# ============================
file_lock = threading.Lock()

# ============================
# SEMÃFORO (LIMITAR BROWSERS)
# ============================
max_browsers = 3  # ğŸ‘ˆ Solo 3 navegadores simultÃ¡neos
browser_semaphore = threading.Semaphore(max_browsers)

# ============================
# INICIAR DRIVER
# ============================
def iniciar_driver():
    options = webdriver.ChromeOptions()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--window-size=1920,1080")
    return webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

# ============================
# DESCARGA DE IMAGEN (CRITICAL SECTION)
# ============================
def descargar_imagen(url, path):
    try:
        img = requests.get(url, timeout=5).content
        
        # ----- SECCIÃ“N CRÃTICA -----
        with file_lock:  # protege escritura
            with open(path, "wb") as f:
                f.write(img)

    except:
        pass

# ============================
# FUNCIÃ“N HILO: SCRAPING
# ============================
def scrapear(producto):
    # ----- SEMÃFORO -----
    with browser_semaphore:  # Espera si hay mÃ¡s de 3 navegadores abiertos

        driver = iniciar_driver()
        url = f"https://listado.mercadolibre.com.co/{producto}"
        driver.get(url)
        time.sleep(3)

        # SCROLL
        last_height = driver.execute_script("return document.body.scrollHeight")
        for _ in range(6):
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(1.8)
            new_height = driver.execute_script("return document.body.scrollHeight")
            if new_height == last_height:
                break
            last_height = new_height

        # Carpeta
        carpeta = os.path.join(BASE_DIR, producto.replace(" ", "_"))
        os.makedirs(carpeta, exist_ok=True)

        # ImÃ¡genes
        imgs = driver.find_elements(By.TAG_NAME, "img")
        contador = 0

        for img in imgs:
            src = img.get_attribute("src") or img.get_attribute("data-src") or img.get_attribute("srcset")

            if src and "http" in src:
                if "srcset" in src:
                    src = src.split(" ")[0]

                path = os.path.join(carpeta, f"{producto}_{contador}.jpg")
                descargar_imagen(src, path)
                contador += 1

            if contador >= 200:
                break

        driver.quit()  # liberar navegador

        print(f"âœ” {producto} â†’ {contador} imÃ¡genes descargadas.")

# ============================
# CREAR Y EJECUTAR HILOS
# ============================
threads = []
for producto in productos:
    hilo = threading.Thread(target=scrapear, args=(producto,))
    hilo.start()
    threads.append(hilo)

for hilo in threads:
    hilo.join()

print("\nFINALIZADO\n")

``` 
Este script:

Abre Mercado Libre
 Busca cada producto
 Descarga hasta 200 imÃ¡genes por categorÃ­a
 Crea carpetas automÃ¡ticamente
 Usa Selenium + Hilos de forma profesional

# Estructura de Salida del Scraping

Una vez ejecutado, automÃ¡ticamente se genera:

scraping/
â”‚
â””â”€â”€ images/
    â”œâ”€â”€ raspberry/
    â”‚     â”œâ”€â”€ img_001.jpg
    â”‚     â”œâ”€â”€ img_002.jpg
    â”‚     â””â”€â”€ ...
    â”œâ”€â”€ osciloscopio/
    â”œâ”€â”€ generador de seÃ±ales/
    â”œâ”€â”€ transistor/
    â”œâ”€â”€ bombilla/
    â””â”€â”€ ...


Cada carpeta contiene 200 imÃ¡genes limpias obtenidas desde la web.

# Resultados del proceso

Al finalizar, el script imprime:

<img width="542" height="247" alt="image" src="https://github.com/user-attachments/assets/c0a2cfb6-65f2-4167-9368-47fd3f722024" />

 # CÃ³mo ejecutar el scraping
1. Instala dependencias
```python
pip install selenium webdriver-manager requests
``` 
2. Ejecuta el script
```python
python mercado_libre.py
``` 
3. Espera que los hilos terminen

Las imÃ¡genes aparecerÃ¡n en scraping/images/.

# ConclusiÃ³n del Punto 1

El sistema desarrollado cumple todos los requerimientos establecidos:

- Web Scraping con Selenium
- BÃºsqueda de mÃ¡s de 10 elementos electrÃ³nicos
- Descarga masiva de mÃ¡s de 200 imÃ¡genes por categorÃ­a
- Uso explÃ­cito y correcto de:

Hilos

SecciÃ³n crÃ­tica

SemÃ¡foro

Mutex

- Arquitectura profesional lista para ETL, clasificaciÃ³n e integraciÃ³n en Docker
- DocumentaciÃ³n clara y tÃ©cnica para evaluaciÃ³n acadÃ©mica

Este punto es la base del proyecto completo, permitiendo construir la base de imÃ¡genes que alimentarÃ¡ el modelo de clasificaciÃ³n (punto 2) y el sistema de detecciÃ³n en tiempo real (puntos 3 y 4).

# PUNTO 2 â€” Desarrollo Completo del ETL (ExtracciÃ³n, TransformaciÃ³n y Carga)

El objetivo del segundo punto es construir un pipeline ETL profesional que permita:

Organizar y limpiar las imÃ¡genes obtenidas en el scraping.

Detectar archivos corruptos o ilegibles.

Preprocesar y estandarizar todo el dataset.

Transformar cada imagen a un formato Ã³ptimo para clasificaciÃ³n.

Cargar la informaciÃ³n procesada en una estructura final lista para entrenar un modelo.

Este apartado documenta toda la arquitectura creada, sus mÃ³dulos y el flujo de datos paso a paso.


# Arquitectura General del ETL

El pipeline se divide en 3 mÃ³dulos principales:

ExtracciÃ³n â†’ obtenciÃ³n de imÃ¡genes desde el directorio de scraping.

TransformaciÃ³n â†’ limpieza, validaciÃ³n y preprocesamiento de cada imagen.

Carga â†’ almacenamiento ordenado en directorios por clase + exportaciÃ³n de metadat

# 2.1. MÃ³dulo de ExtracciÃ³n

Objetivo: Leer todas las imÃ¡genes descargadas en el punto 1 y validarlas previo al procesamiento.

 Se recorren las carpetas generadas por el scraping:

scraping/images/<nombre_de_clase>/


 Se cuentan todas las imÃ¡genes de cada categorÃ­a.
 Se detectan archivos daÃ±ados mostrando advertencias como:

 # 2.2. MÃ³dulo de TransformaciÃ³n

Este mÃ³dulo ejecuta:

 1. Limpieza y validaciÃ³n

Se intenta abrir cada imagen con OpenCV.

Si falla â†’ se descarta automÃ¡ticamente.

Se evita cargar imÃ¡genes con tamaÃ±o incorrecto o corruptas.

# 2.3 EstandarizaciÃ³n

Cada imagen se transforma mediante:

Redimensionamiento a 224Ã—224 px.

NormalizaciÃ³n de valores entre 0 y 1.

ConversiÃ³n a formato .npy optimizado para ML.

GeneraciÃ³n de un hash MD5 por imagen
Esto permite:

Detectar duplicados

Evitar procesar imÃ¡genes repetidas

Mantener un dataset limpio y sin ruido

 AquÃ­ insertas la imagen donde se muestran los duplicados omitidos:

Ejemplo del mensaje real:
 ```python
 Duplicado omitido (hash repetido): etl/data/processed/transistor/transistor_90.jpg.npy
```

# 3. Manejo multihilo (threads)

Para acelerar el proceso, cada clase se procesa en paralelo:

Un hilo por categorÃ­a (raspberry, osciloscopio, fuente, etc.)

Mutex para operaciones crÃ­ticas

SincronizaciÃ³n de escritura en disco

Esto reduce radicalmente el tiempo total del ETL.

# 2.3. MÃ³dulo de Carga

Luego de validar y transformar todas las imÃ¡genes:

 Se guardan las imÃ¡genes limpias en:
etl/data/processed/<nombre_de_clase>/

 Se registran estadÃ­sticas globales:

NÃºmero de imÃ¡genes finales por categorÃ­a

Total final del dataset

NÃºmero de duplicados eliminados

ImÃ¡genes descartadas por corrupciÃ³n

 AquÃ­ insertas tu imagen donde se ve la finalizaciÃ³n con total 1850 imÃ¡genes:

Ejemplo real:

 Clase 'transistor' cargada correctamente.
 Carga finalizada. Total imÃ¡genes registradas: 1850

# Estructura final generada

etl/
 â”œâ”€â”€ data/
 â”‚    â”œâ”€â”€ raw/
 â”‚    â”œâ”€â”€ processed/
 â”‚    â”‚     â”œâ”€â”€ raspberry/
 â”‚    â”‚     â”œâ”€â”€ osciloscopio/
 â”‚    â”‚     â”œâ”€â”€ transistor/
 â”‚    â”‚     â”œâ”€â”€ generador_de_seÃ±ales/
 â”‚    â”‚     â””â”€â”€ â€¦
 â”‚    â””â”€â”€ metadata.json
 â”œâ”€â”€ etl_extract.py
 â”œâ”€â”€ etl_transform.py
 â””â”€â”€ etl_load.py

 # CÃ³digo del ETL (resumen tÃ©cnico)
 TransformaciÃ³n (etl_transform.py)
  ```python
# Procesamiento: resize, normalizaciÃ³n y hash
image = cv2.resize(image, (224, 224))
image = image.astype("float32") / 255.0

hash_value = hashlib.md5(image.tobytes()).hexdigest()

output_path = f"{processed_dir}/{filename}.npy"
np.save(output_path, image)
 ```

 Carga (etl_load.py)
 ```python
if hash_value in hash_registry[class_name]:
    print(f"âš ï¸ Duplicado omitido (hash repetido): {output_file}")
else:
    hash_registry[class_name].add(hash_value)
    np.save(output_file, image)
 ```

 Conclusiones del ETL

El dataset quedÃ³ completamente limpio, sin archivos corruptos.

Se eliminaron centenas de imÃ¡genes duplicadas mediante hashing.

El proceso final contiene 1850 imÃ¡genes vÃ¡lidas, perfectas para entrenamiento.

La arquitectura ETL es profesional, modular y escalable, lista para integrarse con el modelo del Punto 3.

# ImÃ¡genes

<img width="876" height="437" alt="image" src="https://github.com/user-attachments/assets/1e53dcbe-7128-4060-a0f9-eaa577819b9b" />

# PUNTO 3 â€” Sistema de ClasificaciÃ³n de Objetos + DetecciÃ³n y Velocidad de Personas (Modelo Simple + OpenCV HOG + Multithreading)

El tercer punto del proyecto implementa un sistema completo de visiÃ³n artificial en tiempo real que:

Clasifica herramientas de laboratorio usando un modelo propio entrenado con el dataset del ETL.

Detecta personas, genera identificaciÃ³n por ID y calcula su velocidad instantÃ¡nea.

Corre dos anÃ¡lisis paralelos (objetos y velocidad) usando la misma cÃ¡mara, gracias a hilos, semÃ¡foros y locks.

Despliega todo el sistema dentro de una aplicaciÃ³n Streamlit con dos pestaÃ±as interactivas.

La arquitectura final combina procesamiento de imÃ¡genes, machine learning simple, detecciÃ³n HOG, tracking, sincronizaciÃ³n por hilos y Streamlit, integrando todo en un entorno estable y profesional.

#  Arquitectura General del Punto 3

El sistema estÃ¡ compuesto por 3 hilos principales:

CamGrabber â†’ productor de frames (un solo hilo para toda la app)

PredictorThread â†’ clasifica herramientas con el modelo entrenado

PeopleSpeedThread â†’ detecta personas, les asigna ID y calcula velocidad

Cada uno opera de forma independiente, pero sincronizados mediante:

Locks â†’ para acceso seguro a los frames compartidos

SemÃ¡foros â†’ para controlar el procesamiento simultÃ¡neo de predicciones

Threads Daemon â†’ para ejecutar tareas en paralelo sin bloquear la UI

# 3.1. Captura de CÃ¡mara â€“ Hilo CamGrabber

Este hilo es el corazÃ³n de la app:
- captura continuamente los frames de la webcam
- los entrega al predictor y al mÃ³dulo de velocidad
  - calcula FPS en tiempo real
 ```python
self.lock = threading.Lock()
self.frame = None

ret, frame = self.cap.read()
with self.lock:
    self.frame = frame.copy()
 ```

Ventajas:

Evita capturas duplicadas

Garantiza que todos los hilos usan el mismo frame sincronizado

Minimiza consumo de CPU y evita retardos


 <img width="730" height="525" alt="image" src="https://github.com/user-attachments/assets/b2dfa864-5b3c-47db-bee8-916d6e451bd3" />


# 3.2. ClasificaciÃ³n de Objetos â€“ Hilo PredictorThread

Este mÃ³dulo usa el modelo entrenado en el Punto 2:

modelo lineal con pesos W y b

extracciÃ³n de caracterÃ­sticas manual con kernels

clasificaciÃ³n sin umbral (siempre muestra la predicciÃ³n)

 Pipeline del predictor:

Convertir frame a escala de grises

Redimensionar a 256Ã—256

Normalizar

Extraer caracterÃ­sticas mediante 3 kernels

Aplicar pooling

Normalizar vector de caracterÃ­sticas

Multiplicar por W y sumar b

Aplicar softmax

Ejemplo de predicciÃ³n overlay:
```python

text = f"{pred_t.pred} ({pred_t.conf:.2f})"
cv2.putText(frame_obj, text, (20,50), ...)

```
<img width="619" height="823" alt="image" src="https://github.com/user-attachments/assets/1a64d7f0-a8c7-4bcb-8e7f-f466677b3ddc" />
<img width="663" height="813" alt="image" src="https://github.com/user-attachments/assets/412e8f0d-a06c-448b-a82a-86f622607dc4" />
<img width="632" height="737" alt="image" src="https://github.com/user-attachments/assets/c2bc143b-eeb9-443a-b4d1-5e75cdf60785" />


3.3. DetecciÃ³n de Personas + Velocidad â€“ Hilo PeopleSpeedThread

Este mÃ³dulo implementa:

Detector HOG de OpenCV (cv2.HOGDescriptor)

AsignaciÃ³n de IDs por cercanÃ­a de centroides

Memoria de Ãºltimos frames

CÃ¡lculo de velocidad por persona

EliminaciÃ³n de tracks desaparecidos

##  CÃ¡lculo de Velocidad del Objeto

La velocidad se calcula como:

**velocidad (px/s) = Î”distancia(px) / Î”tiempo(s)**

Donde:

- **Î”distancia(px)** = diferencia del centroide entre dos frames.
- **Î”tiempo(s)** = tiempo transcurrido entre capturas consecutivas.

### FÃ³rmula utilizada

**distancia_px = âˆš((xâ‚‚ - xâ‚)Â² + (yâ‚‚ - yâ‚)Â²)**  
**velocidad = distancia_px / dt**

### ImplementaciÃ³n en Python

```python
dist_px = ((cx - prev["centroid"][0])**2 + (cy - prev["centroid"][1])**2)**0.5
speed = dist_px / dt

```
# 3.4. Multithreading: Locks + SemÃ¡foros
Locks

Usados para evitar corrupciÃ³n de memoria y lectura simultÃ¡nea del frame.
```python
with self.lock:
    self.frame = frame.copy()
```
 SemÃ¡foros

Controlan cuÃ¡ntas predicciones simultÃ¡neas puede hacer el predictor.
```python
self.sema = threading.Semaphore(1)
```

Esto evita:

saturaciÃ³n del CPU

bloqueos en la lectura de la cÃ¡mara

predicciones repetidas sobre el mismo frame

# 3.5. Interfaz Streamlit con PestaÃ±as DinÃ¡micas

La app presenta dos vistas en tiempo real:

 PestaÃ±a 1: â€œObjetosâ€

Muestra predicciÃ³n del modelo

Superpone la etiqueta y la confianza

Muestra FPS del sistema

PestaÃ±a 2: â€œVelocidadâ€

Muestra bounding boxes de cada persona

Dibuja centroides

Muestra velocidad en px/s

# 3.6. Flujo Completo del Sistema

```mermaid
flowchart TD

    %% Nodos principales
    CAM[Camara]
    GRAB[CamGrabber - Frame Compartido]

    PRED[PredictorThread - Clasificacion]
    SPEED[PeopleSpeedThread - Tracking y Velocidad]

    UI[Streamlit UI]

    %% Indicador de Tracks Activos
    TRACKS[Tracks Activos]

    %% Flujo
    CAM --> GRAB

    GRAB --> PRED
    GRAB --> SPEED

    PRED --> UI
    SPEED --> UI

    SPEED --> TRACKS


```

Conclusiones del Punto 3

Se implementÃ³ un sistema completo de visiÃ³n artificial en tiempo real.

Se integraron dos modelos paralelos:

ClasificaciÃ³n de herramientas

DetecciÃ³n + velocidad de personas

Los hilos funcionan de manera segura mediante locks y semÃ¡foros.

La interfaz en Streamlit es clara, funcional y permite alternar entre vistas sin detener la cÃ¡mara.

Sistema apto para laboratorios inteligentes, robÃ³tica o vigilancia.
