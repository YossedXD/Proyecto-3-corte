# PROYECTO DE TERCER CORTE

# Descripci√≥n General

El primer punto del proyecto consiste en desarrollar un sistema automatizado de Web Scraping capaz de obtener m√≠nimo 200 im√°genes de diferentes herramientas utilizadas en los laboratorios de ingenier√≠a electr√≥nica, tales como:

-Raspberry Pi

-Generador de se√±ales

-Osciloscopio

-Fuente dual

-Destornillador

-Pinzas

-Condensador

-Transistor

-Bombilla

El objetivo final es construir la base de datos visual que alimentar√° los siguientes puntos del proyecto (ETL, clasificaci√≥n, despliegue).

Para garantizar alto rendimiento, el sistema implementa:

Hilos (threads) para paralelismo real.

Sem√°foro para evitar crear demasiadas instancias de navegador.

Mutex (Lock) para proteger las operaciones de escritura en disco.

Selenium + WebDriver Manager para abrir b√∫squedas reales en Mercado Libre y capturar im√°genes de cada producto.

# Arquitectura del Sistema de Scraping

```mermaid
flowchart TD
    CENTRAL((Sistema de Scraping))

    MAIN[MAIN THREAD]
    WORKER[WORKER THREAD x10]
    DOWN[DOWNLOADER Mutex]

    SUB1[Crea lista de productos]
    SUB2[Lanza hilos en paralelo]

    SUB3[Pide turno al semaforo]
    SUB4[Abre Selenium headless]
    SUB5[Extrae URLs de imagenes]
    SUB6[Envia URLs al downloader]

    SUB7[Descarga imagenes]
    SUB8[Protege escritura]
    SUB9[Guarda archivos por producto]

    CENTRAL --> MAIN
    CENTRAL --> WORKER
    CENTRAL --> DOWN

    MAIN --> SUB1
    MAIN --> SUB2

    WORKER --> SUB3
    WORKER --> SUB4
    WORKER --> SUB5
    WORKER --> SUB6

    DOWN --> SUB7
    DOWN --> SUB8
    DOWN --> SUB9

    MAIN --> WORKER --> DOWN



```
Descarga segura mediante la librer√≠a requests.

Este dise√±o permite recolectar miles de im√°genes de forma r√°pida, controlada y segura.


##  Tecnolog√≠as Utilizadas

| Tecnolog√≠a        | Uso                                                     |
|------------------|----------------------------------------------------------|
| **Python 3**     | L√≥gica principal del sistema                             |
| **Selenium**     | Navegaci√≥n web real y extracci√≥n de im√°genes             |
| **WebDriver Manager** | Gesti√≥n autom√°tica de ChromeDriver                  |
| **Requests**     | Descarga directa de im√°genes                             |
| **Threads (Hilos)** | Paralelismo para aumentar velocidad                   |
| **Semaphore**    | Controla el n√∫mero de navegadores simult√°neos            |
| **Lock / Mutex** | Evita conflictos en la escritura a disco                 |


# Modelo de Concurrencia: Hilos + Sem√°foro + Mutex

Este scraping fue dise√±ado con ingenier√≠a de concurrencia, no simplemente con Python secuencial.

Hilos (threads)

Cada producto se procesa en un hilo independiente.
Esto permite descargar im√°genes de varios productos simult√°neamente.

 Sem√°foro (threading.Semaphore)

Abrir muchos navegadores Chrome simult√°neamente consume mucha RAM.
Por eso, se limita a 3 navegadores m√°ximo en paralelo:

``` python

browser_semaphore = threading.Semaphore(3)

```
Solo 3 hilos pueden abrir Selenium a la vez.
Los dem√°s esperan su turno.

 Mutex (threading.Lock)

Cuando varios hilos descargan im√°genes al mismo tiempo existe riesgo de:

 -Archivos corruptos

-Colisiones escribiendo el mismo nombre

-Directorios bloqueados

Para evitarlo:

``` python

with file_lock:
    with open(filename, "wb") as f:
        f.write(img.content)

```
Solo un hilo escribe a disco a la vez ‚Üí 100% seguro.

# C√≥digo utilizado para el scraping

``` python


from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
import threading
import time
import os
import requests

# ============================
# LISTA DE PRODUCTOS
# ============================
productos = [
    "multimetro", "raspberry", "generador de se√±ales", "osciloscopio",
    "fuente dual", "destornillador", "pinzas", "condensador",
    "transistor", "bombilla"
]

# ============================
# CARPETA BASE
# ============================
BASE_DIR = "scraping/images/"
os.makedirs(BASE_DIR, exist_ok=True)

# ============================
# MUTEX (SECCI√ìN CR√çTICA DE ESCRITURA)
# ============================
file_lock = threading.Lock()

# ============================
# SEM√ÅFORO (LIMITAR BROWSERS)
# ============================
max_browsers = 3  # üëà Solo 3 navegadores simult√°neos
browser_semaphore = threading.Semaphore(max_browsers)

# ============================
# INICIAR DRIVER
# ============================
def iniciar_driver():
    options = webdriver.ChromeOptions()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--window-size=1920,1080")
    return webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

# ============================
# DESCARGA DE IMAGEN (CRITICAL SECTION)
# ============================
def descargar_imagen(url, path):
    try:
        img = requests.get(url, timeout=5).content
        
        # ----- SECCI√ìN CR√çTICA -----
        with file_lock:  # protege escritura
            with open(path, "wb") as f:
                f.write(img)

    except:
        pass

# ============================
# FUNCI√ìN HILO: SCRAPING
# ============================
def scrapear(producto):
    # ----- SEM√ÅFORO -----
    with browser_semaphore:  # Espera si hay m√°s de 3 navegadores abiertos

        driver = iniciar_driver()
        url = f"https://listado.mercadolibre.com.co/{producto}"
        driver.get(url)
        time.sleep(3)

        # SCROLL
        last_height = driver.execute_script("return document.body.scrollHeight")
        for _ in range(6):
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(1.8)
            new_height = driver.execute_script("return document.body.scrollHeight")
            if new_height == last_height:
                break
            last_height = new_height

        # Carpeta
        carpeta = os.path.join(BASE_DIR, producto.replace(" ", "_"))
        os.makedirs(carpeta, exist_ok=True)

        # Im√°genes
        imgs = driver.find_elements(By.TAG_NAME, "img")
        contador = 0

        for img in imgs:
            src = img.get_attribute("src") or img.get_attribute("data-src") or img.get_attribute("srcset")

            if src and "http" in src:
                if "srcset" in src:
                    src = src.split(" ")[0]

                path = os.path.join(carpeta, f"{producto}_{contador}.jpg")
                descargar_imagen(src, path)
                contador += 1

            if contador >= 200:
                break

        driver.quit()  # liberar navegador

        print(f"‚úî {producto} ‚Üí {contador} im√°genes descargadas.")

# ============================
# CREAR Y EJECUTAR HILOS
# ============================
threads = []
for producto in productos:
    hilo = threading.Thread(target=scrapear, args=(producto,))
    hilo.start()
    threads.append(hilo)

for hilo in threads:
    hilo.join()

print("\nFINALIZADO\n")

``` 
Este script:

Abre Mercado Libre
 Busca cada producto
 Descarga hasta 200 im√°genes por categor√≠a
 Crea carpetas autom√°ticamente
 Usa Selenium + Hilos de forma profesional

# Estructura de Salida del Scraping

Una vez ejecutado, autom√°ticamente se genera:

scraping/
‚îÇ
‚îî‚îÄ‚îÄ images/
    ‚îú‚îÄ‚îÄ raspberry/
    ‚îÇ     ‚îú‚îÄ‚îÄ img_001.jpg
    ‚îÇ     ‚îú‚îÄ‚îÄ img_002.jpg
    ‚îÇ     ‚îî‚îÄ‚îÄ ...
    ‚îú‚îÄ‚îÄ osciloscopio/
    ‚îú‚îÄ‚îÄ generador de se√±ales/
    ‚îú‚îÄ‚îÄ transistor/
    ‚îú‚îÄ‚îÄ bombilla/
    ‚îî‚îÄ‚îÄ ...


Cada carpeta contiene 200 im√°genes limpias obtenidas desde la web.

# Resultados del proceso

Al finalizar, el script imprime:

<img width="542" height="247" alt="image" src="https://github.com/user-attachments/assets/c0a2cfb6-65f2-4167-9368-47fd3f722024" />

 # C√≥mo ejecutar el scraping
1. Instala dependencias
```python
pip install selenium webdriver-manager requests
``` 
2. Ejecuta el script
```python
python mercado_libre.py
``` 
3. Espera que los hilos terminen

Las im√°genes aparecer√°n en scraping/images/.

# Conclusi√≥n del Punto 1

El sistema desarrollado cumple todos los requerimientos establecidos:

- Web Scraping con Selenium
- B√∫squeda de m√°s de 10 elementos electr√≥nicos
- Descarga masiva de m√°s de 200 im√°genes por categor√≠a
- Uso expl√≠cito y correcto de:

Hilos

Secci√≥n cr√≠tica

Sem√°foro

Mutex

- Arquitectura profesional lista para ETL, clasificaci√≥n e integraci√≥n en Docker
- Documentaci√≥n clara y t√©cnica para evaluaci√≥n acad√©mica

Este punto es la base del proyecto completo, permitiendo construir la base de im√°genes que alimentar√° el modelo de clasificaci√≥n (punto 2) y el sistema de detecci√≥n en tiempo real (puntos 3 y 4).

# PUNTO 2 ‚Äî Desarrollo Completo del ETL (Extracci√≥n, Transformaci√≥n y Carga)

El objetivo del segundo punto es construir un pipeline ETL profesional que permita:

Organizar y limpiar las im√°genes obtenidas en el scraping.

Detectar archivos corruptos o ilegibles.

Preprocesar y estandarizar todo el dataset.

Transformar cada imagen a un formato √≥ptimo para clasificaci√≥n.

Cargar la informaci√≥n procesada en una estructura final lista para entrenar un modelo.

Este apartado documenta toda la arquitectura creada, sus m√≥dulos y el flujo de datos paso a paso.


# Arquitectura General del ETL

El pipeline se divide en 3 m√≥dulos principales:

Extracci√≥n ‚Üí obtenci√≥n de im√°genes desde el directorio de scraping.

Transformaci√≥n ‚Üí limpieza, validaci√≥n y preprocesamiento de cada imagen.

Carga ‚Üí almacenamiento ordenado en directorios por clase + exportaci√≥n de metadat

# 2.1. M√≥dulo de Extracci√≥n

Objetivo: Leer todas las im√°genes descargadas en el punto 1 y validarlas previo al procesamiento.

 Se recorren las carpetas generadas por el scraping:

scraping/images/<nombre_de_clase>/


 Se cuentan todas las im√°genes de cada categor√≠a.
 Se detectan archivos da√±ados mostrando advertencias como:

 # 2.2. M√≥dulo de Transformaci√≥n

Este m√≥dulo ejecuta:

 1. Limpieza y validaci√≥n

Se intenta abrir cada imagen con OpenCV.

Si falla ‚Üí se descarta autom√°ticamente.

Se evita cargar im√°genes con tama√±o incorrecto o corruptas.

# 2.3 Estandarizaci√≥n

Cada imagen se transforma mediante:

Redimensionamiento a 224√ó224 px.

Normalizaci√≥n de valores entre 0 y 1.

Conversi√≥n a formato .npy optimizado para ML.

Generaci√≥n de un hash MD5 por imagen
Esto permite:

Detectar duplicados

Evitar procesar im√°genes repetidas

Mantener un dataset limpio y sin ruido

 Aqu√≠ insertas la imagen donde se muestran los duplicados omitidos:

Ejemplo del mensaje real:
 ```python
 Duplicado omitido (hash repetido): etl/data/processed/transistor/transistor_90.jpg.npy
```

# 3. Manejo multihilo (threads)

Para acelerar el proceso, cada clase se procesa en paralelo:

Un hilo por categor√≠a (raspberry, osciloscopio, fuente, etc.)

Mutex para operaciones cr√≠ticas

Sincronizaci√≥n de escritura en disco

Esto reduce radicalmente el tiempo total del ETL.

# 2.3. M√≥dulo de Carga

Luego de validar y transformar todas las im√°genes:

 Se guardan las im√°genes limpias en:
etl/data/processed/<nombre_de_clase>/

 Se registran estad√≠sticas globales:

N√∫mero de im√°genes finales por categor√≠a

Total final del dataset

N√∫mero de duplicados eliminados

Im√°genes descartadas por corrupci√≥n

 Aqu√≠ insertas tu imagen donde se ve la finalizaci√≥n con total 1850 im√°genes:

Ejemplo real:

 Clase 'transistor' cargada correctamente.
 Carga finalizada. Total im√°genes registradas: 1850

# Estructura final generada

etl/
 ‚îú‚îÄ‚îÄ data/
 ‚îÇ    ‚îú‚îÄ‚îÄ raw/
 ‚îÇ    ‚îú‚îÄ‚îÄ processed/
 ‚îÇ    ‚îÇ     ‚îú‚îÄ‚îÄ raspberry/
 ‚îÇ    ‚îÇ     ‚îú‚îÄ‚îÄ osciloscopio/
 ‚îÇ    ‚îÇ     ‚îú‚îÄ‚îÄ transistor/
 ‚îÇ    ‚îÇ     ‚îú‚îÄ‚îÄ generador_de_se√±ales/
 ‚îÇ    ‚îÇ     ‚îî‚îÄ‚îÄ ‚Ä¶
 ‚îÇ    ‚îî‚îÄ‚îÄ metadata.json
 ‚îú‚îÄ‚îÄ etl_extract.py
 ‚îú‚îÄ‚îÄ etl_transform.py
 ‚îî‚îÄ‚îÄ etl_load.py

 # C√≥digo del ETL (resumen t√©cnico)
 Transformaci√≥n (etl_transform.py)
  ```python
# Procesamiento: resize, normalizaci√≥n y hash
image = cv2.resize(image, (224, 224))
image = image.astype("float32") / 255.0

hash_value = hashlib.md5(image.tobytes()).hexdigest()

output_path = f"{processed_dir}/{filename}.npy"
np.save(output_path, image)
 ```

 Carga (etl_load.py)
 ```python
if hash_value in hash_registry[class_name]:
    print(f"‚ö†Ô∏è Duplicado omitido (hash repetido): {output_file}")
else:
    hash_registry[class_name].add(hash_value)
    np.save(output_file, image)
 ```

 Conclusiones del ETL

El dataset qued√≥ completamente limpio, sin archivos corruptos.

Se eliminaron centenas de im√°genes duplicadas mediante hashing.

El proceso final contiene 1850 im√°genes v√°lidas, perfectas para entrenamiento.

La arquitectura ETL es profesional, modular y escalable, lista para integrarse con el modelo del Punto 3.

# Im√°genes

<img width="876" height="437" alt="image" src="https://github.com/user-attachments/assets/1e53dcbe-7128-4060-a0f9-eaa577819b9b" />

# PUNTO 3 ‚Äî Sistema de Clasificaci√≥n de Objetos + Detecci√≥n y Velocidad de Personas (Modelo Simple + OpenCV HOG + Multithreading)

El tercer punto del proyecto implementa un sistema completo de visi√≥n artificial en tiempo real que:

Clasifica herramientas de laboratorio usando un modelo propio entrenado con el dataset del ETL.

Detecta personas, genera identificaci√≥n por ID y calcula su velocidad instant√°nea.

Corre dos an√°lisis paralelos (objetos y velocidad) usando la misma c√°mara, gracias a hilos, sem√°foros y locks.

Despliega todo el sistema dentro de una aplicaci√≥n Streamlit con dos pesta√±as interactivas.

La arquitectura final combina procesamiento de im√°genes, machine learning simple, detecci√≥n HOG, tracking, sincronizaci√≥n por hilos y Streamlit, integrando todo en un entorno estable y profesional.

#  Arquitectura General del Punto 3

El sistema est√° compuesto por 3 hilos principales:

CamGrabber ‚Üí productor de frames (un solo hilo para toda la app)

PredictorThread ‚Üí clasifica herramientas con el modelo entrenado

PeopleSpeedThread ‚Üí detecta personas, les asigna ID y calcula velocidad

Cada uno opera de forma independiente, pero sincronizados mediante:

Locks ‚Üí para acceso seguro a los frames compartidos

Sem√°foros ‚Üí para controlar el procesamiento simult√°neo de predicciones

Threads Daemon ‚Üí para ejecutar tareas en paralelo sin bloquear la UI

# 3.1. Captura de C√°mara ‚Äì Hilo CamGrabber

Este hilo es el coraz√≥n de la app:
- captura continuamente los frames de la webcam
- los entrega al predictor y al m√≥dulo de velocidad
  - calcula FPS en tiempo real
 ```python
self.lock = threading.Lock()
self.frame = None

ret, frame = self.cap.read()
with self.lock:
    self.frame = frame.copy()
 ```

Ventajas:

Evita capturas duplicadas

Garantiza que todos los hilos usan el mismo frame sincronizado

Minimiza consumo de CPU y evita retardos


 <img width="730" height="525" alt="image" src="https://github.com/user-attachments/assets/b2dfa864-5b3c-47db-bee8-916d6e451bd3" />


# 3.2. Clasificaci√≥n de Objetos ‚Äì Hilo PredictorThread

Este m√≥dulo usa el modelo entrenado en el Punto 2:

modelo lineal con pesos W y b

extracci√≥n de caracter√≠sticas manual con kernels

clasificaci√≥n sin umbral (siempre muestra la predicci√≥n)

 Pipeline del predictor:

Convertir frame a escala de grises

Redimensionar a 256√ó256

Normalizar

Extraer caracter√≠sticas mediante 3 kernels

Aplicar pooling

Normalizar vector de caracter√≠sticas

Multiplicar por W y sumar b

Aplicar softmax

Ejemplo de predicci√≥n overlay:
```python

text = f"{pred_t.pred} ({pred_t.conf:.2f})"
cv2.putText(frame_obj, text, (20,50), ...)

```
<img width="619" height="823" alt="image" src="https://github.com/user-attachments/assets/1a64d7f0-a8c7-4bcb-8e7f-f466677b3ddc" />
<img width="663" height="813" alt="image" src="https://github.com/user-attachments/assets/412e8f0d-a06c-448b-a82a-86f622607dc4" />
<img width="632" height="737" alt="image" src="https://github.com/user-attachments/assets/c2bc143b-eeb9-443a-b4d1-5e75cdf60785" />


3.3. Detecci√≥n de Personas + Velocidad ‚Äì Hilo PeopleSpeedThread

Este m√≥dulo implementa:

Detector HOG de OpenCV (cv2.HOGDescriptor)

Asignaci√≥n de IDs por cercan√≠a de centroides

Memoria de √∫ltimos frames

C√°lculo de velocidad por persona

Eliminaci√≥n de tracks desaparecidos

##  C√°lculo de Velocidad del Objeto

La velocidad se calcula como:

**velocidad (px/s) = Œîdistancia(px) / Œîtiempo(s)**

Donde:

- **Œîdistancia(px)** = diferencia del centroide entre dos frames.
- **Œîtiempo(s)** = tiempo transcurrido entre capturas consecutivas.

### F√≥rmula utilizada

**distancia_px = ‚àö((x‚ÇÇ - x‚ÇÅ)¬≤ + (y‚ÇÇ - y‚ÇÅ)¬≤)**  
**velocidad = distancia_px / dt**

### Implementaci√≥n en Python

```python
dist_px = ((cx - prev["centroid"][0])**2 + (cy - prev["centroid"][1])**2)**0.5
speed = dist_px / dt

```
# 3.4. Multithreading: Locks + Sem√°foros
Locks

Usados para evitar corrupci√≥n de memoria y lectura simult√°nea del frame.
```python
with self.lock:
    self.frame = frame.copy()
```
 Sem√°foros

Controlan cu√°ntas predicciones simult√°neas puede hacer el predictor.
```python
self.sema = threading.Semaphore(1)
```

Esto evita:

saturaci√≥n del CPU

bloqueos en la lectura de la c√°mara

predicciones repetidas sobre el mismo frame

# 3.5. Interfaz Streamlit con Pesta√±as Din√°micas

La app presenta dos vistas en tiempo real:

 Pesta√±a 1: ‚ÄúObjetos‚Äù

Muestra predicci√≥n del modelo

Superpone la etiqueta y la confianza

Muestra FPS del sistema

Pesta√±a 2: ‚ÄúVelocidad‚Äù

Muestra bounding boxes de cada persona

Dibuja centroides

Muestra velocidad en px/s

# 3.6. Flujo Completo del Sistema

```mermaid
flowchart TD

    %% Nodos principales
    CAM[Camara]
    GRAB[CamGrabber - Frame Compartido]

    PRED[PredictorThread - Clasificacion]
    SPEED[PeopleSpeedThread - Tracking y Velocidad]

    UI[Streamlit UI]

    %% Indicador de Tracks Activos
    TRACKS[Tracks Activos]

    %% Flujo
    CAM --> GRAB

    GRAB --> PRED
    GRAB --> SPEED

    PRED --> UI
    SPEED --> UI

    SPEED --> TRACKS


```

Conclusiones del Punto 3

Se implement√≥ un sistema completo de visi√≥n artificial en tiempo real.

Se integraron dos modelos paralelos:

Clasificaci√≥n de herramientas

Detecci√≥n + velocidad de personas

Los hilos funcionan de manera segura mediante locks y sem√°foros.

La interfaz en Streamlit es clara, funcional y permite alternar entre vistas sin detener la c√°mara.

Sistema apto para laboratorios inteligentes, rob√≥tica o vigilancia.

# 4. Despliegue de la Aplicaci√≥n (Docker + Streamlit WebApp)

Este proyecto fue completamente contenedorizado, ejecutado y desplegado usando Docker y Streamlit, cumpliendo todos los requisitos del cuarto punto del entregable. A continuaci√≥n se muestra el procedimiento completo.

#  4.1. Construcci√≥n del contenedor Docker

El proyecto incluye un Dockerfile totalmente funcional.
Para construir la imagen localmente:
```python
docker build -t streamlit-detector .

```
Una vez finalizada la compilaci√≥n, confirmar que la imagen existe:
```python
docker images
```

 La imagen debe aparecer como streamlit-detector.

 <img width="1280" height="650" alt="image" src="https://github.com/user-attachments/assets/c155f91d-423f-4be8-b6ae-cb07151bbf1b" />


 # 4.2. Ejecuci√≥n local del contenedor

Para ejecutar el contenedor en tu propio equipo, us√© el siguiente comando:

docker run -p 8501:8501 --name visionapp streamlit-detector


Luego, abrir en el navegador:

 http://localhost:8501

Donde se cargan simult√°neamente:

- Detector de Velocidad (MediaPipe + tracking)

- Detector de Objetos (modelo simple entrenado)

- Interfaz Streamlit con ambas vistas lado a lado

### 4.3. Despliegue de la imagen en Docker Hub

La imagen final fue subida al repositorio p√∫blico:

Docker Hub:
 https://hub.docker.com/r/jefersonmvp/streamlit-detector

Para descargarla y ejecutarla desde cualquier equipo:
```python
docker pull jefersonmvp/streamlit-detector
docker run -p 8501:8501 jefersonmvp/streamlit-detector
```

#  4.4. Despliegue de la aplicaci√≥n v√≠a Streamlit Web

La aplicaci√≥n tambi√©n se despliega v√≠a Streamlit Web, permitiendo acceso desde navegador sin instalaci√≥n local:

Contiene:

Interfaz doble (Velocidad + Objetos)

Hilos independientes

FPS en tiempo real

Sincronizaci√≥n entre pipelines

Procesamiento simult√°neo por la misma c√°mara

(https://hub.docker.com/r/jefersonmvp/streamlit-detector)

# 4.5. Evidencias del despliegue
üîß Ejecuci√≥n correcta del contenedor

<img width="1280" height="655" alt="image" src="https://github.com/user-attachments/assets/47f3da5f-094b-4f9a-a61a-07af2699ccd2" />

 Streamlit funcionando con doble vista

<img width="1278" height="855" alt="image" src="https://github.com/user-attachments/assets/71bce428-0eb8-4870-980e-3118a7bba636" />

<img width="1280" height="655" alt="image" src="https://github.com/user-attachments/assets/e72dd60d-f3a1-46ea-8d33-16bcd378cc01" />

 Detector de Objetos funcionando

<img width="1280" height="574" alt="image" src="https://github.com/user-attachments/assets/2770e177-0901-4268-83f2-b606ad2080eb" />

<img width="1280" height="554" alt="image" src="https://github.com/user-attachments/assets/5401add8-41dc-467a-88cc-d0fe7c2eba9e" />

<img width="1280" height="606" alt="image" src="https://github.com/user-attachments/assets/59060e1d-bb4a-475e-870f-ae1de67f5649" />

<img width="1280" height="621" alt="image" src="https://github.com/user-attachments/assets/4534a711-4fd3-4616-8527-ced27c50efb7" />

<img width="1280" height="598" alt="image" src="https://github.com/user-attachments/assets/70ba03c7-0d02-4238-9f6c-a810ccc9c485" />

<img width="1280" height="574" alt="image" src="https://github.com/user-attachments/assets/967fddb4-cb3f-4e42-a7c1-76accb72dcae" />

<img width="1280" height="641" alt="image" src="https://github.com/user-attachments/assets/72aad00c-4cb7-46a1-bf75-d13222009a86" />

<img width="1280" height="596" alt="image" src="https://github.com/user-attachments/assets/af524f05-e7d2-4f8c-bdfa-3b1d60e97541" />

<img width="1280" height="636" alt="image" src="https://github.com/user-attachments/assets/64f39c9f-a317-4861-a963-a2b6b4036e14" />


Detector de Velocidad funcionando

<img width="1176" height="864" alt="image" src="https://github.com/user-attachments/assets/be4cc872-133c-4071-9db4-f819dee178e8" />

<img width="1278" height="855" alt="image" src="https://github.com/user-attachments/assets/e6875ffc-49e9-4fec-8246-c598ee9faff4" />


### 4.6. Conclusiones del despliegue

El proyecto es completamente portable gracias a Docker.

La aplicaci√≥n puede ejecutarse sin dependencias en cualquier m√°quina.

El c√≥digo integra simult√°neamente dos sistemas avanzados de visi√≥n por computador en producci√≥n.

La documentaci√≥n y el despliegue cumplen todos los requisitos del punto 4 del entregable.
